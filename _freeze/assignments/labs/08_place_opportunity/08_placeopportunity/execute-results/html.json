{
  "hash": "4056b90e78087764890bd5b950d2e03d",
  "result": {
    "markdown": "---\ntitle: \"Place Opportunity\"\nsidebar: false\ntoc: true\ntoc-depth: 4\npage-layout: full\nbibliography: ../references.bib\ncsl: ../apa-6th-edition.csl\nexecute: \n  cache: true\nformat: \n  html:\n    code-fold: show\n    code-overflow: wrap\n    code-tools:\n      source: true\n      toggle: false\n      caption: none\nfig-responsive: true\neditor: visual\n---\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-1_155bf2043bc5b8979e6f5413f67de28f'}\n\n:::\n\n\n## Introduction\n\nIn this lab, we'll extend our knowledge of opportunity maps, and more generally in standardizing and creating indexes from data. This strategy is in some ways an extension of the strategy we used to measure neighborhood change. Our measurement of neighborhood change, however, focused on a single dimension of change - income. In this case, we'll produce a *multidimensional* measure of change.\n\nAs we have discussed in class, opportunity maps and other indexes are commonly used to be able to illustrate the distribution of resources across space and over time. These types of indexes are designed to be *multidimensional*, and therefore require a strong theoretical framework connecting concepts related to opportunity to indicators or measures designed to proxy or represent these concepts.\n\n## Goals\n\nThis lab introduces you to the following: \n\n- Common methods for standardizing and constructing indexes from demographic data \n\n- Basic concepts associated with relational joins between datasets \n\n- Reinforces and provides a means of practicing data visualization and presentation\n\n## Core Concepts\n\n### R and Rstudio\n\n-   `across()`\n-   `reduce()`\n-   `rowwise()`\n-   `scale()`\n\nLet's get going...\n\n## Github Lab Repository\n\nIf you have not already done so, follow [this link](https://classroom.github.com/a/HefJuFJW) to accept the lab Github Classroom assignment repository.\n\n## Download and Prepare Data for Opportunity Mapping\n\nThe [National Housing Conference brief](https://uofi.box.com/s/icccjttbig4mq94nbi123b6x3o33a4zi) which you read for Tuesday outlines several suggested data sources for opportunity mapping. For the purpose of learning some of the methods associated with opportunity mapping, we'll work with three primary data sources:\n\n-   [U.S. Census Bureau - American Community Survey](http://www.data.census.gov)\n-   [HUD Location Affordability Index (version 3.0)](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3)\n-   [EPA EJSCREEN](https://www.epa.gov/ejscreen/download-ejscreen-data)\n\nYou should independently explore the documentation for these datasets and their indicators - there is a *treasure trove* of documentation to look at. When possible, download data documentation to your docuemtnation project folder.\n\nWe'll divide these data into a few conceptual categories commonly seen in opportunity maps: \n\n- Education \n\n- Housing Characteristics \n\n- Social Capital \n\n- Public Health and Safety \n\n- Employment and Workforce \n\n- Transportation and Mobility\n\n| Category                    | Indicator                                        | Data Source                                                                                 |\n|-----------------|-------------------|------------------------------------|\n| Education                   | Population with a High School Diploma or greater | [ACS](https://data.census.gov)                                                              |\n| Education                   | Population with a Bachelor's Degree or greater   | [ACS](https://data.census.gov)                                                              |\n| Housing Characteristics     | Median Home Value                                | [ACS](https://data.census.gov)                                                              |\n| Housing Characteristics     | Median Gross Rent                                | [HUD LAI](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3) |\n| Housing Characteristics     | Percentage Single Family Housing Units           | [HUD LAI](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3) |\n| Housing Characteristics     | Gross Rent as Percentage of Income               | [ACS](https://data.census.gov)                                                              |\n| Housing Characteristics     | Housing Cost Burden                              | [ACS](https://data.census.gov)                                                              |\n| Housing Characteristics     | Residential Vacancy Rate                         | [ACS](https://data.census.gov)                                                              |\n| Social Capital              | Population Age 25 - 44                           | [ACS](https://data.census.gov)                                                              |\n| Social Capital              | Median Household Income                          | [ACS](https://data.census.gov)                                                              |\n| Social Capital              | Percent of Households in Poverty                 | [ACS](https://data.census.gov)                                                              |\n| Social Capital              | Percentage of Owner-Occupied Housing Units       | [ACS](https://data.census.gov)                                                              |\n| Employment and Worforce     | Job Density                                      | [HUD LAI](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3) |\n| Employment and Worforce     | Retail Density                                   | [HUD LAI](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3) |\n| Transportation and Mobility | Median Commute Time                              | [HUD LAI](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3) |\n| Transportation and Mobility | Public Transit Use (Journey to work)             | [HUD LAI](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3) |\n| Public Health and Safety    | NATA Cancer Risk Index                           | [EPA EJSCREEN (2022)](https://www.epa.gov/ejscreen/download-ejscreen-data)                  |\n| Public Health and Safety    | NATA Respiratory Hazard Index                    | [EPA EJSCREEN (2022)](https://www.epa.gov/ejscreen/download-ejscreen-data)                  |\n| Public Health and Safety    | Traffic Proximity and Volume                     | [EPA EJSCREEN (2022)](https://www.epa.gov/ejscreen/download-ejscreen-data)                  |\n| Public Health and Safety    | Particulate Matter                               | [EPA EJSCREEN(2022)](https://www.epa.gov/ejscreen/download-ejscreen-data)                   |\n\nI have provided download links for the EJSCREEN and LAI data. We will use `tidycensus` to load ACS data.\n\n### ACS Data\n\nLet's start by loading some ACS data:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-2_b3d6a7ef230d2018515680f3022105a0'}\n\n:::\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-3_a92d75820355a584b3570c6de406f194'}\n\n```{.r .cell-code}\nDL_Year<-2020\nsurvey <- \"acs5\"\nstate<-c(\"NY\")\nsource(\"scripts/1_Get_ACS.R\")\n```\n:::\n\n\nThis should look familiar - we have a script kept in the scripts folder with general code to download selected variables from the American Community Survey. Rather than placing this code in our notebook, we can use the `source()` command to run the script in its entirety. We are defining the variables (api_key, DL_Year, survey, state) in our notebook, so that these can be referenced when the script is running.\n\nWe have downloaded a lot of ACS data here at the census tract level for all tracts in Illinois:\n\n| Table  | Description             |\n|--------|-------------------------|\n| B01001 | Age and Population      |\n| B02001 | Race                    |\n| B03001 | Ethnicity               |\n| B05002 | Foreign Born            |\n| B11001 | Female Headed Household |\n| B17001 | Poverty Rate            |\n| B19013 | Median Household Income |\n| B25002 | Residential Vacancy     |\n| B25003 | Housing Tenure          |\n| B25077 | Median Home Value       |\n| B25106 | Housing Cost Burden     |\n\nI went ahead and turned this raw data into some selected indicators:\n\n| Table  | Label        | Description                                           |\n|--------------|--------------|---------------------------------------------|\n| B01001 | under18      | Proportion of Population under 18                     |\n| B01001 | over65       | Proportion of Population over 65                      |\n| B01001 | P_Female     | Proportion of Population female                       |\n| B01001 | Pop          | Total Population size                                 |\n| B02001 | PWhite       | Proportion Population White                           |\n| B02001 | PBlack       | Proportion Population Black                           |\n| B02001 | PAIAN        | Proportion Population AIAN                            |\n| B02001 | PAsian       | Proportion Population Asian                           |\n| B02001 | PNonwhite    | Proportion Population Nonwhite                        |\n| B03001 | PLatino      | Proportion Population Latino Ethnicity (Of all Races) |\n| B05002 | PForeignborn | Proportion Population Foreign Born                    |\n| B19013 | MHHI         | Median Household Income                               |\n| B11001 | P_FHHH       | Proportion Female Headed Households                   |\n| B17001 | Pov          | Proportion Households Below Poverty                   |\n| B25003 | P_Own        | Proportion Owner Occupied Housing Units               |\n| B25077 | MHV          | Median Home Value                                     |\n| B25106 | CostBurden   | Housing Cost Burden                                   |\n| B25002 | Rvac         | Residential Vacancy Rate                              |\n\n#### Join ACS Data\n\nNow that we have these individual tables downloaded, we need to combine these together into a single dataset. We've done this many times in the past using `left_join()` but only with respect to two datasets at a time. Let's introduce an alternative strategy here, using the purrr package's `reduce()` function combined with `left_join()`.\n\nFirst, here's the way we might accomplish this as we have in the past:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-4_396e1c6a9ee4a1923d4ab6aae378fce5'}\n\n```{.r .cell-code}\nacs_data<-left_join(B01001, B02001, by=\"GEOID\")\nacs_data<-left_join(acs_data, B03001, by=\"GEOID\")\nacs_data<-left_join(acs_data, B05002, by=\"GEOID\")\nacs_data<-left_join(acs_data, B11001, by=\"GEOID\")\nacs_data<-left_join(acs_data, B17001, by=\"GEOID\")\nacs_data<-left_join(acs_data, B19013, by=\"GEOID\")\nacs_data<-left_join(acs_data, B25002, by=\"GEOID\")\nacs_data<-left_join(acs_data, B25003, by=\"GEOID\")\nacs_data<-left_join(acs_data, B25077, by=\"GEOID\")\nacs_data<-left_join(acs_data, B25106, by=\"GEOID\")\n```\n:::\n\n\nThis works just fine, but there's a lot of repition of code here with so many data frames.\n\nNow let's look at how we can implement the same thing using `reduce()`:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-5_bc7cdbe897ed2f3d4963887c8141caa5'}\n\n```{.r .cell-code}\nacs_data <- list(B01001, B02001, B03001, B05002, B11001, B17001, B19013, B25002, B25003, B25077, B25106) |> \n  reduce(left_join, by = \"GEOID\")\n```\n:::\n\n\nIn this case, we create a list containing each of the data frames we want to join together (note that we don't put these in quotes since they're objects and not names). We then use the `reduce()` command and tell reduce that we want to perform a left join and also supply the common variable name.\n\nBut what is `reduce()` really doing here? If you look at it's documentation (`?reduce`), you'll see that:\n\n`reduce()` is an operation that combines elements of a vector into a single value. The combination is driven by .f, a binary function, and takes two values and returns a single value: Reducing f over 1:3 computes the values f(f(1,2), 3).\n\nSo if we are doing a left join, this is essentially doing the following:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-6_04a87424cf585595ffc80167fd2edf76'}\n\n```{.r .cell-code}\nacs_data <- left_join(df1, df2)\nacs_data <- left_join(acs_data, df3)\n```\n:::\n\n\nAnd on and on until reduce has iterated through all elements of the list. This helps us cut down on repetitious code.\n\nInspecting our handiwork, our acs_data table (for which we downloaded tract-level data for New York state has 5,411 observations and 19 variables:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-7_8cce1c151f2936f7e22e8abd4b394078'}\n\n```{.r .cell-code}\nstr(acs_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntibble [5,411 × 19] (S3: tbl_df/tbl/data.frame)\n $ GEOID       : chr [1:5411] \"36011040600\" \"36011040700\" \"36011040800\" \"36011040900\" ...\n $ under18     : num [1:5411] 0.183 0.187 0.192 0.218 0.2 ...\n $ over65      : num [1:5411] 0.234 0.216 0.182 0.18 0.165 ...\n $ Pop         : num [1:5411] 3400 3633 4668 3683 3088 ...\n $ P_Female    : num [1:5411] 0.504 0.518 0.419 0.476 0.456 ...\n $ PWhite      : num [1:5411] 0.945 0.978 0.841 0.982 0.94 ...\n $ PBlack      : num [1:5411] 0.037647 0 0.113325 0.000272 0 ...\n $ PAIAN       : num [1:5411] 0 0 0 0.000815 0.000324 ...\n $ PAsian      : num [1:5411] 0.00235 0 0.00771 0.00434 0.0068 ...\n $ PNonwhite   : num [1:5411] 0.0547 0.022 0.1594 0.0185 0.0599 ...\n $ PLatino     : num [1:5411] 0.01647 0.00798 0.02571 0.02607 0.04955 ...\n $ PForeignborn: num [1:5411] 0.0176 0.0242 0.0176 0.0141 0.0385 ...\n $ P_FHHH      : num [1:5411] 0.0931 0.0486 0.089 0.0989 0.0638 ...\n $ Pov         : num [1:5411] 0.0507 0.049 0.0991 0.158 0.087 ...\n $ MHHI        : num [1:5411] 84330 93493 64811 66711 73182 ...\n $ Rvac        : num [1:5411] 0.0898 0.1612 0.3182 0.176 0.246 ...\n $ P_Own       : num [1:5411] 0.917 0.935 0.828 0.872 0.836 ...\n $ MHV         : num [1:5411] 186500 174900 147100 142700 147600 ...\n $ CostBurden  : num [1:5411] 0.224 0.206 0.283 0.246 0.172 ...\n```\n:::\n:::\n\n\nWhile we're at it, let's do a little cleaning up. We have a lot of data frames which are now consolidated into acs_data. We can delete other objects from our environment using `rm()`\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-8_9a8e73b46c38b903ab841c9d47676471'}\n\n```{.r .cell-code}\nrm(B01001, B02001, B03001, B05002, B11001, B17001, B19013, B25002, B25003, B25077, B25106)\n```\n:::\n\n\n### Location Affordability Index Data\n\nLet's download the HUD Location Affordability Index data from [here](https://hudgis-hud.opendata.arcgis.com/datasets/location-affordability-index-v-3/explore?location=1.864944%2C0.315564%2C0.98). We can then load it directly.\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-9_ecd338c04e3ad1ae776ab0a9b878f590'}\n\n```{.r .cell-code}\nLAI <- read_csv(\"data_raw/Location_Affordability_Index_v.3.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 73763 Columns: 444\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (7): GEOID, STATE, COUNTY, TRACT, CNTY_FIPS, STUSAB, area_type\ndbl (437): OBJECTID, households, owner_occupied_hu, renter_occupied_hu, pct_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nLet's go ahead and select the following variables (our variables of interest) and overwrite the initial file:\n\n-   GEOID\n-   pct_transit_j2w\n-   median_gross_rent\n-   pct_hu_1_detatched\n-   job_density_simple\n-   retail_density_simple\n-   median_commute\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-10_ed59b56660b4286f42a3879f039f94cf'}\n\n```{.r .cell-code}\nLAI<-LAI |>  select(GEOID, \n                    STUSAB,\n                    pct_transit_j2w,\n                    median_gross_rent,\n                    pct_hu_1_detached,\n                    job_density_simple,\n                    retail_density_simple,\n                    median_commute\n                    )\n```\n:::\n\n\n### EJSCREEN Data\n\nWe can download the EJSCREEN data [here](https://gaftp.epa.gov/EJSCREEN/2020/). Unlike the LAI data which we could read directly from the .csv file, the EJSCREEN data will need to be downloaded and unzipped before it can be used.\n\nWe'll use the `read_csv()` function from the `readr` package to load raw EJSCREEN data, located in the \"data\" folder. Load these into an object called \"ejscreen\":\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-11_033e35f434408588dd28ba9da0b1b0e3'}\n\n:::\n\n\nInspect the data. Let's select a subset of the variables in the data which we'll work more with. Based upon our framework, we'll select the following variables and overwrite the original ejscreen object with our selection:\n\n-   ID\n-   ACSTOTPOP\n-   CANCER\n-   RESP\n-   PTRAF\n-   PM25\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-12_7936bac642698b306e2fc6be920ddbbd'}\n\n```{.r .cell-code}\nejscreen<-ejscreen |> \n  select(ID,\n        ACSTOTPOP,\n        CANCER,\n        RESP,\n        PTRAF,\n        PM25)\n```\n:::\n\n\n## Joining the Three Datasets\n\nOk - we're getting somewhere, I promise! We now have three datasets - acs_data, which contains tract-level data for New York state, LAI which contains *tract-level data* for the entire US, and ejscreen which contains *block group level data* for the US. We're so close to joining these together and indexing the data!\n\n### Creating Tract Data from Block Groups\n\nOne thing, though - we need to convert our ejscreen block groups data into tracts. Block groups are geographic subdivisions of tracts. Fortunately for us, Census FIPS codes are hierarchical - the combined state-county-tract-blockgroup variable called \"ID\" in ejscreen contains the tract FIPS code: - State (2 characters) - County (3 characters) - Tract (6 characters) - Block Group (1 character)\n\nOk, this is all well and good - how do we use this knowledge to combine things together? We could simply average the block group values together to approximate a tract-level average. At the same time, block groups are likely to have different populations. Given this potential heterogeneity, let's use the population weighted average of those block group characteristics to constitute our tract characteristics.\n\nTo aggregate our block group data, we need to extract the tract characters from the ID column, and then we can `group_by()` and `summarise` our data based upon the tract FIPS code. Base R fortunately has a function called `substr()` (substring) which can handle the extraction for us:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-13_93ce8238caef70461f71fc3637a34076'}\n\n```{.r .cell-code}\nejscreen<-ejscreen |> \n  mutate(GEOID = substr(ID, 0, 11))\n```\n:::\n\n\nWhat happened here? We're creating a new column called GEOID, and then invoking substr. We tell that function that we want a substring from the ID field, and then we say 0, 11, where 0 is the first position if we were counting from the left of the first character in the ID variable, and 11 is the last character that we want (remember, the combined FIPS code is 12 characters long, and we want all but the last character).\n\nAnd now we can use `group_by()` and `summarise()` to group together the data into census tract level aggregates. We can use `weighted.mean()` to calculate... weight for it... the weighted average (professor humor)! GEOID contains our combined state-county-tract FIPS code, ACSTOTPOP contains out population for the purpose of weighting, and we want to calculate averages for CANCER, RESP, PTRAF, and PM25. Figure out how to get that done.\n\nSneak preview - you're going to hit an error - think about what rows might need to be removed to calculate a weighted average:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-14_6b3b533f1933ec52a5108a15f16781a4'}\n\n```{.r .cell-code}\nejscreen<-ejscreen |>  \n  filter(ACSTOTPOP != 0, CANCER != \"None\") |> \n  group_by(GEOID) |>  \n  summarise(\n  CANCER = weighted.mean(as.numeric(CANCER), ACSTOTPOP),\n  RESP = weighted.mean(as.numeric(RESP), ACSTOTPOP),\n  PTRAF = weighted.mean(PTRAF, ACSTOTPOP),\n  PM25 = weighted.mean(as.numeric(PM25), ACSTOTPOP))\n```\n:::\n\n\nOk - now we have around 73,000 tract-level observations for the EPA data - not too far off from what we have for the LAI data. Both of these datasets include observations for the entire US, while our ACS data only contains observations for New York State. Using your newfound knowledge of how to join data together based upon a common column, create a new object named dataset which contains combined ACS, ejscreen, and LAI data for Illinois census tracts:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-15_2f5d5a25b30f0c99474db07291af86c5'}\n\n```{.r .cell-code}\ndataset<- list(acs_data,  LAI, ejscreen) |> reduce(left_join, by=\"GEOID\")\n\ndataset |> \n  head() |> \n  gt()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"wrgrmzjxmm\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#wrgrmzjxmm table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#wrgrmzjxmm thead, #wrgrmzjxmm tbody, #wrgrmzjxmm tfoot, #wrgrmzjxmm tr, #wrgrmzjxmm td, #wrgrmzjxmm th {\n  border-style: none;\n}\n\n#wrgrmzjxmm p {\n  margin: 0;\n  padding: 0;\n}\n\n#wrgrmzjxmm .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#wrgrmzjxmm .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#wrgrmzjxmm .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#wrgrmzjxmm .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#wrgrmzjxmm .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#wrgrmzjxmm .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#wrgrmzjxmm .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#wrgrmzjxmm .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#wrgrmzjxmm .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#wrgrmzjxmm .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#wrgrmzjxmm .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#wrgrmzjxmm .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#wrgrmzjxmm .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#wrgrmzjxmm .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#wrgrmzjxmm .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wrgrmzjxmm .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#wrgrmzjxmm .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#wrgrmzjxmm .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#wrgrmzjxmm .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wrgrmzjxmm .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#wrgrmzjxmm .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wrgrmzjxmm .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#wrgrmzjxmm .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wrgrmzjxmm .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#wrgrmzjxmm .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#wrgrmzjxmm .gt_left {\n  text-align: left;\n}\n\n#wrgrmzjxmm .gt_center {\n  text-align: center;\n}\n\n#wrgrmzjxmm .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#wrgrmzjxmm .gt_font_normal {\n  font-weight: normal;\n}\n\n#wrgrmzjxmm .gt_font_bold {\n  font-weight: bold;\n}\n\n#wrgrmzjxmm .gt_font_italic {\n  font-style: italic;\n}\n\n#wrgrmzjxmm .gt_super {\n  font-size: 65%;\n}\n\n#wrgrmzjxmm .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#wrgrmzjxmm .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#wrgrmzjxmm .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#wrgrmzjxmm .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#wrgrmzjxmm .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#wrgrmzjxmm .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#wrgrmzjxmm .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"GEOID\">GEOID</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"under18\">under18</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"over65\">over65</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Pop\">Pop</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"P_Female\">P_Female</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PWhite\">PWhite</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PBlack\">PBlack</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PAIAN\">PAIAN</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PAsian\">PAsian</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PNonwhite\">PNonwhite</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PLatino\">PLatino</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PForeignborn\">PForeignborn</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"P_FHHH\">P_FHHH</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Pov\">Pov</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"MHHI\">MHHI</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"Rvac\">Rvac</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"P_Own\">P_Own</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"MHV\">MHV</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"CostBurden\">CostBurden</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"STUSAB\">STUSAB</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"pct_transit_j2w\">pct_transit_j2w</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"median_gross_rent\">median_gross_rent</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"pct_hu_1_detached\">pct_hu_1_detached</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"job_density_simple\">job_density_simple</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"retail_density_simple\">retail_density_simple</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"median_commute\">median_commute</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"CANCER\">CANCER</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"RESP\">RESP</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PTRAF\">PTRAF</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_right\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"PM25\">PM25</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"GEOID\" class=\"gt_row gt_right\">36011040600</td>\n<td headers=\"under18\" class=\"gt_row gt_right\">0.1829412</td>\n<td headers=\"over65\" class=\"gt_row gt_right\">0.2341176</td>\n<td headers=\"Pop\" class=\"gt_row gt_right\">3400</td>\n<td headers=\"P_Female\" class=\"gt_row gt_right\">0.5044118</td>\n<td headers=\"PWhite\" class=\"gt_row gt_right\">0.9452941</td>\n<td headers=\"PBlack\" class=\"gt_row gt_right\">0.0376470588</td>\n<td headers=\"PAIAN\" class=\"gt_row gt_right\">0.0000000000</td>\n<td headers=\"PAsian\" class=\"gt_row gt_right\">0.002352941</td>\n<td headers=\"PNonwhite\" class=\"gt_row gt_right\">0.05470588</td>\n<td headers=\"PLatino\" class=\"gt_row gt_right\">0.016470588</td>\n<td headers=\"PForeignborn\" class=\"gt_row gt_right\">0.01764706</td>\n<td headers=\"P_FHHH\" class=\"gt_row gt_right\">0.09307876</td>\n<td headers=\"Pov\" class=\"gt_row gt_right\">0.05068672</td>\n<td headers=\"MHHI\" class=\"gt_row gt_right\">84330</td>\n<td headers=\"Rvac\" class=\"gt_row gt_right\">0.08979001</td>\n<td headers=\"P_Own\" class=\"gt_row gt_right\">0.9172633</td>\n<td headers=\"MHV\" class=\"gt_row gt_right\">186500</td>\n<td headers=\"CostBurden\" class=\"gt_row gt_right\">0.2235481</td>\n<td headers=\"STUSAB\" class=\"gt_row gt_left\">NY</td>\n<td headers=\"pct_transit_j2w\" class=\"gt_row gt_right\">0.7344093</td>\n<td headers=\"median_gross_rent\" class=\"gt_row gt_right\">869</td>\n<td headers=\"pct_hu_1_detached\" class=\"gt_row gt_right\">92.82640</td>\n<td headers=\"job_density_simple\" class=\"gt_row gt_right\">0.071023683</td>\n<td headers=\"retail_density_simple\" class=\"gt_row gt_right\">0.006993935</td>\n<td headers=\"median_commute\" class=\"gt_row gt_right\">16.00</td>\n<td headers=\"CANCER\" class=\"gt_row gt_right\">19.70603</td>\n<td headers=\"RESP\" class=\"gt_row gt_right\">0.2238431</td>\n<td headers=\"PTRAF\" class=\"gt_row gt_right\">76.199249</td>\n<td headers=\"PM25\" class=\"gt_row gt_right\">6.211746</td></tr>\n    <tr><td headers=\"GEOID\" class=\"gt_row gt_right\">36011040700</td>\n<td headers=\"under18\" class=\"gt_row gt_right\">0.1871731</td>\n<td headers=\"over65\" class=\"gt_row gt_right\">0.2163501</td>\n<td headers=\"Pop\" class=\"gt_row gt_right\">3633</td>\n<td headers=\"P_Female\" class=\"gt_row gt_right\">0.5183044</td>\n<td headers=\"PWhite\" class=\"gt_row gt_right\">0.9779796</td>\n<td headers=\"PBlack\" class=\"gt_row gt_right\">0.0000000000</td>\n<td headers=\"PAIAN\" class=\"gt_row gt_right\">0.0000000000</td>\n<td headers=\"PAsian\" class=\"gt_row gt_right\">0.000000000</td>\n<td headers=\"PNonwhite\" class=\"gt_row gt_right\">0.02202037</td>\n<td headers=\"PLatino\" class=\"gt_row gt_right\">0.007982384</td>\n<td headers=\"PForeignborn\" class=\"gt_row gt_right\">0.02422241</td>\n<td headers=\"P_FHHH\" class=\"gt_row gt_right\">0.04855024</td>\n<td headers=\"Pov\" class=\"gt_row gt_right\">0.04899532</td>\n<td headers=\"MHHI\" class=\"gt_row gt_right\">93493</td>\n<td headers=\"Rvac\" class=\"gt_row gt_right\">0.16119910</td>\n<td headers=\"P_Own\" class=\"gt_row gt_right\">0.9352664</td>\n<td headers=\"MHV\" class=\"gt_row gt_right\">174900</td>\n<td headers=\"CostBurden\" class=\"gt_row gt_right\">0.2063385</td>\n<td headers=\"STUSAB\" class=\"gt_row gt_left\">NY</td>\n<td headers=\"pct_transit_j2w\" class=\"gt_row gt_right\">0.0000000</td>\n<td headers=\"median_gross_rent\" class=\"gt_row gt_right\">787</td>\n<td headers=\"pct_hu_1_detached\" class=\"gt_row gt_right\">94.71613</td>\n<td headers=\"job_density_simple\" class=\"gt_row gt_right\">0.084031686</td>\n<td headers=\"retail_density_simple\" class=\"gt_row gt_right\">0.000897934</td>\n<td headers=\"median_commute\" class=\"gt_row gt_right\">13.95</td>\n<td headers=\"CANCER\" class=\"gt_row gt_right\">19.58912</td>\n<td headers=\"RESP\" class=\"gt_row gt_right\">0.2248577</td>\n<td headers=\"PTRAF\" class=\"gt_row gt_right\">8.835063</td>\n<td headers=\"PM25\" class=\"gt_row gt_right\">6.179412</td></tr>\n    <tr><td headers=\"GEOID\" class=\"gt_row gt_right\">36011040800</td>\n<td headers=\"under18\" class=\"gt_row gt_right\">0.1919452</td>\n<td headers=\"over65\" class=\"gt_row gt_right\">0.1820908</td>\n<td headers=\"Pop\" class=\"gt_row gt_right\">4668</td>\n<td headers=\"P_Female\" class=\"gt_row gt_right\">0.4190231</td>\n<td headers=\"PWhite\" class=\"gt_row gt_right\">0.8406170</td>\n<td headers=\"PBlack\" class=\"gt_row gt_right\">0.1133247644</td>\n<td headers=\"PAIAN\" class=\"gt_row gt_right\">0.0000000000</td>\n<td headers=\"PAsian\" class=\"gt_row gt_right\">0.007712082</td>\n<td headers=\"PNonwhite\" class=\"gt_row gt_right\">0.15938303</td>\n<td headers=\"PLatino\" class=\"gt_row gt_right\">0.025706941</td>\n<td headers=\"PForeignborn\" class=\"gt_row gt_right\">0.01756641</td>\n<td headers=\"P_FHHH\" class=\"gt_row gt_right\">0.08900524</td>\n<td headers=\"Pov\" class=\"gt_row gt_right\">0.09908915</td>\n<td headers=\"MHHI\" class=\"gt_row gt_right\">64811</td>\n<td headers=\"Rvac\" class=\"gt_row gt_right\">0.31816154</td>\n<td headers=\"P_Own\" class=\"gt_row gt_right\">0.8278796</td>\n<td headers=\"MHV\" class=\"gt_row gt_right\">147100</td>\n<td headers=\"CostBurden\" class=\"gt_row gt_right\">0.2827225</td>\n<td headers=\"STUSAB\" class=\"gt_row gt_left\">NY</td>\n<td headers=\"pct_transit_j2w\" class=\"gt_row gt_right\">0.1046997</td>\n<td headers=\"median_gross_rent\" class=\"gt_row gt_right\">621</td>\n<td headers=\"pct_hu_1_detached\" class=\"gt_row gt_right\">75.63869</td>\n<td headers=\"job_density_simple\" class=\"gt_row gt_right\">0.021437169</td>\n<td headers=\"retail_density_simple\" class=\"gt_row gt_right\">0.003085479</td>\n<td headers=\"median_commute\" class=\"gt_row gt_right\">20.63</td>\n<td headers=\"CANCER\" class=\"gt_row gt_right\">17.56237</td>\n<td headers=\"RESP\" class=\"gt_row gt_right\">0.1972023</td>\n<td headers=\"PTRAF\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"PM25\" class=\"gt_row gt_right\">6.092557</td></tr>\n    <tr><td headers=\"GEOID\" class=\"gt_row gt_right\">36011040900</td>\n<td headers=\"under18\" class=\"gt_row gt_right\">0.2180288</td>\n<td headers=\"over65\" class=\"gt_row gt_right\">0.1802878</td>\n<td headers=\"Pop\" class=\"gt_row gt_right\">3683</td>\n<td headers=\"P_Female\" class=\"gt_row gt_right\">0.4759707</td>\n<td headers=\"PWhite\" class=\"gt_row gt_right\">0.9815368</td>\n<td headers=\"PBlack\" class=\"gt_row gt_right\">0.0002715178</td>\n<td headers=\"PAIAN\" class=\"gt_row gt_right\">0.0008145534</td>\n<td headers=\"PAsian\" class=\"gt_row gt_right\">0.004344285</td>\n<td headers=\"PNonwhite\" class=\"gt_row gt_right\">0.01846321</td>\n<td headers=\"PLatino\" class=\"gt_row gt_right\">0.026065707</td>\n<td headers=\"PForeignborn\" class=\"gt_row gt_right\">0.01411892</td>\n<td headers=\"P_FHHH\" class=\"gt_row gt_right\">0.09890110</td>\n<td headers=\"Pov\" class=\"gt_row gt_right\">0.15799510</td>\n<td headers=\"MHHI\" class=\"gt_row gt_right\">66711</td>\n<td headers=\"Rvac\" class=\"gt_row gt_right\">0.17600453</td>\n<td headers=\"P_Own\" class=\"gt_row gt_right\">0.8722527</td>\n<td headers=\"MHV\" class=\"gt_row gt_right\">142700</td>\n<td headers=\"CostBurden\" class=\"gt_row gt_right\">0.2458791</td>\n<td headers=\"STUSAB\" class=\"gt_row gt_left\">NY</td>\n<td headers=\"pct_transit_j2w\" class=\"gt_row gt_right\">0.1057314</td>\n<td headers=\"median_gross_rent\" class=\"gt_row gt_right\">733</td>\n<td headers=\"pct_hu_1_detached\" class=\"gt_row gt_right\">70.25913</td>\n<td headers=\"job_density_simple\" class=\"gt_row gt_right\">0.004264647</td>\n<td headers=\"retail_density_simple\" class=\"gt_row gt_right\">0.000176875</td>\n<td headers=\"median_commute\" class=\"gt_row gt_right\">18.12</td>\n<td headers=\"CANCER\" class=\"gt_row gt_right\">17.22243</td>\n<td headers=\"RESP\" class=\"gt_row gt_right\">0.1934044</td>\n<td headers=\"PTRAF\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"PM25\" class=\"gt_row gt_right\">6.108516</td></tr>\n    <tr><td headers=\"GEOID\" class=\"gt_row gt_right\">36011041001</td>\n<td headers=\"under18\" class=\"gt_row gt_right\">0.2001295</td>\n<td headers=\"over65\" class=\"gt_row gt_right\">0.1648316</td>\n<td headers=\"Pop\" class=\"gt_row gt_right\">3088</td>\n<td headers=\"P_Female\" class=\"gt_row gt_right\">0.4562824</td>\n<td headers=\"PWhite\" class=\"gt_row gt_right\">0.9400907</td>\n<td headers=\"PBlack\" class=\"gt_row gt_right\">0.0000000000</td>\n<td headers=\"PAIAN\" class=\"gt_row gt_right\">0.0003238342</td>\n<td headers=\"PAsian\" class=\"gt_row gt_right\">0.006800518</td>\n<td headers=\"PNonwhite\" class=\"gt_row gt_right\">0.05990933</td>\n<td headers=\"PLatino\" class=\"gt_row gt_right\">0.049546632</td>\n<td headers=\"PForeignborn\" class=\"gt_row gt_right\">0.03853627</td>\n<td headers=\"P_FHHH\" class=\"gt_row gt_right\">0.06375839</td>\n<td headers=\"Pov\" class=\"gt_row gt_right\">0.08699902</td>\n<td headers=\"MHHI\" class=\"gt_row gt_right\">73182</td>\n<td headers=\"Rvac\" class=\"gt_row gt_right\">0.24604681</td>\n<td headers=\"P_Own\" class=\"gt_row gt_right\">0.8355705</td>\n<td headers=\"MHV\" class=\"gt_row gt_right\">147600</td>\n<td headers=\"CostBurden\" class=\"gt_row gt_right\">0.1719799</td>\n<td headers=\"STUSAB\" class=\"gt_row gt_left\">NA</td>\n<td headers=\"pct_transit_j2w\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"median_gross_rent\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"pct_hu_1_detached\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"job_density_simple\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"retail_density_simple\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"median_commute\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"CANCER\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"RESP\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"PTRAF\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"PM25\" class=\"gt_row gt_right\">NA</td></tr>\n    <tr><td headers=\"GEOID\" class=\"gt_row gt_right\">36011041002</td>\n<td headers=\"under18\" class=\"gt_row gt_right\">0.1115152</td>\n<td headers=\"over65\" class=\"gt_row gt_right\">0.1921212</td>\n<td headers=\"Pop\" class=\"gt_row gt_right\">1650</td>\n<td headers=\"P_Female\" class=\"gt_row gt_right\">0.4678788</td>\n<td headers=\"PWhite\" class=\"gt_row gt_right\">0.8909091</td>\n<td headers=\"PBlack\" class=\"gt_row gt_right\">0.0151515152</td>\n<td headers=\"PAIAN\" class=\"gt_row gt_right\">0.0042424242</td>\n<td headers=\"PAsian\" class=\"gt_row gt_right\">0.013333333</td>\n<td headers=\"PNonwhite\" class=\"gt_row gt_right\">0.10909091</td>\n<td headers=\"PLatino\" class=\"gt_row gt_right\">0.065454545</td>\n<td headers=\"PForeignborn\" class=\"gt_row gt_right\">0.02424242</td>\n<td headers=\"P_FHHH\" class=\"gt_row gt_right\">0.04838710</td>\n<td headers=\"Pov\" class=\"gt_row gt_right\">0.09794239</td>\n<td headers=\"MHHI\" class=\"gt_row gt_right\">79167</td>\n<td headers=\"Rvac\" class=\"gt_row gt_right\">0.35416667</td>\n<td headers=\"P_Own\" class=\"gt_row gt_right\">0.8440860</td>\n<td headers=\"MHV\" class=\"gt_row gt_right\">169900</td>\n<td headers=\"CostBurden\" class=\"gt_row gt_right\">0.1487455</td>\n<td headers=\"STUSAB\" class=\"gt_row gt_left\">NA</td>\n<td headers=\"pct_transit_j2w\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"median_gross_rent\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"pct_hu_1_detached\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"job_density_simple\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"retail_density_simple\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"median_commute\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"CANCER\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"RESP\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"PTRAF\" class=\"gt_row gt_right\">NA</td>\n<td headers=\"PM25\" class=\"gt_row gt_right\">NA</td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\n\nNow that we have our base dataset together, we can filter to our area of interest, in this case, the boroughs that make up New York City:\n\n| FIPS Code | County Name     | Borough Name  |\n|-----------|-----------------|---------------|\n| 36047     | Kings County    | Brooklyn      |\n| 36005     | Bronx County    | Bronx         |\n| 36081     | Queens County   | Queens        |\n| 36085     | Richmond County | Staten Island |\n| 36061     | New York County | Manhattan     |\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-16_e55a99e1645342905aefd02b3bd16d45'}\n\n```{.r .cell-code}\ndataset <- dataset |> \n  filter(substr(GEOID, 0, 5) %in% c(\"36047\", \"36005\", \"36081\", \"36085\", \"36061\"))\n```\n:::\n\n\nThe above code uses `substr()` to pull out the first 5 characters from the GEOID field (the combined state and county FIPS codes) and then matches them against the FIPS codes for the five boroughs of New York City.\n\n## Create Standardized Scores\n\nRemembering back to your high school or college statistics class, a Z-score (or standardized score) can be be calculated by subtracting from a given observation the mean of all observations and then dividing by the standard deviation of all observations.\n\nRecall:\n\n$z = \\frac{x-\\mu}{\\sigma}$ where: $x$ is the individual observation we want to standardize $\\mu$ is the population mean $\\sigma$ is the population standard deviation\n\nFind the mean and standard deviation for a variable in our dataset and manually calculate a z-score (just for fun).\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-17_cd24d211bb8fb77aca0377a911c39526'}\n\n```{.r .cell-code}\ndataset |> \n  summarise(\n  under18_mean = mean(under18, na.rm=TRUE), \n  under18_sd = sd(under18, na.rm=TRUE),\n  z_under18 = (under18 - under18_mean)/under18_sd\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,327 × 3\n   under18_mean under18_sd z_under18\n          <dbl>      <dbl>     <dbl>\n 1        0.205     0.0773   0.960  \n 2        0.205     0.0773   1.98   \n 3        0.205     0.0773   0.572  \n 4        0.205     0.0773  -0.254  \n 5        0.205     0.0773   0.980  \n 6        0.205     0.0773   0.706  \n 7        0.205     0.0773  -0.253  \n 8        0.205     0.0773   0.865  \n 9        0.205     0.0773  -0.00949\n10        0.205     0.0773   0.539  \n# ℹ 2,317 more rows\n```\n:::\n:::\n\n\nFor the first observation, the value for Under 18 is 27.9 percent. The average value for tracts in Illinois is 27.9 percent, and the standard deviation is 7.73. The standardized score of .960 indicates that the observation is .96 of a standard deviation above the mean. There's absolutely nothing wrong with doing this manually, however, we can use the `scale()` function to do the same thing:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-18_85d98c2e25f35ffd8430bc47d4611e7a'}\n\n```{.r .cell-code}\ndataset |>  \n  mutate(under18 = scale(under18))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,327 × 30\n   GEOID       under18[,1] over65   Pop P_Female PWhite PBlack   PAIAN PAsian\n   <chr>             <dbl>  <dbl> <dbl>    <dbl>  <dbl>  <dbl>   <dbl>  <dbl>\n 1 36047009202     0.960   0.0747  3453    0.514 0.296  0.0568 0.00782 0.300 \n 2 36047009401     1.98    0.0763  2293    0.515 0.0754 0.0754 0       0.690 \n 3 36047009402     0.572   0.0885  2746    0.548 0.172  0.0138 0       0.695 \n 4 36047009600    -0.254   0.132   5858    0.570 0.362  0.0446 0.00751 0.340 \n 5 36047009800     0.980   0.0864  6021    0.498 0.153  0.0485 0       0.383 \n 6 36047010000     0.706   0.128   5978    0.541 0.264  0.0238 0.0110  0.423 \n 7 36047010100    -0.253   0.0842  3944    0.508 0.510  0.0418 0.0327  0.0903\n 8 36047010200     0.865   0.126   4844    0.515 0.124  0.0142 0       0.705 \n 9 36047010401    -0.00949 0.125   2152    0.487 0.106  0.0279 0       0.838 \n10 36047010402     0.539   0.148   2256    0.523 0.0638 0      0       0.879 \n# ℹ 2,317 more rows\n# ℹ 21 more variables: PNonwhite <dbl>, PLatino <dbl>, PForeignborn <dbl>,\n#   P_FHHH <dbl>, Pov <dbl>, MHHI <dbl>, Rvac <dbl>, P_Own <dbl>, MHV <dbl>,\n#   CostBurden <dbl>, STUSAB <chr>, pct_transit_j2w <dbl>,\n#   median_gross_rent <dbl>, pct_hu_1_detached <dbl>, job_density_simple <dbl>,\n#   retail_density_simple <dbl>, median_commute <dbl>, CANCER <dbl>,\n#   RESP <dbl>, PTRAF <dbl>, PM25 <dbl>\n```\n:::\n:::\n\n\nThis brings up an important question - what should the reference geography be for our opportunity measures? We narrowed down our dataset to New York City, however, we could have just as easily used the state or the nation. It's important to keep in mind that once we construct Z-scores for our indicators, they are with reference to the distribiotn of values we choose to include. We are using the city of New York City as our point of reference. Using the state as a point of reference may be relevant and useful, especially if we want to make some comparisons across the state. At the same time, the characteristics of New York City and other metropolitan areas are likely to be very different than the balance of the state, and so comparisons for the purpose of standardizing our data may be a bit distorted. Now that we have our reference region selected, we can move forward with standardizing each indicator value.\n\nBefore we do this, it can be useful to provide a more intuitive description of each variable (since most people do not think about indicators in standardized terms). You may recall us previously using commands like `summary()` for basic descriptives.\n\nWe're going to use a variant of the `summarise` command which you've used in the past. `summarise_at()` allows us to select variables to summarise by their name, and will then apply the same function across all of those variables. Let's find the mean for each of the indicator variables in our compiled dataset:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-19_8fdfb069443f5e273f5ef9b3d7974464'}\n\n```{.r .cell-code}\ndataset |> \n  summarise_at(vars(under18:median_commute), mean, na.rm=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 25\n  under18 over65   Pop P_Female PWhite PBlack   PAIAN PAsian PNonwhite PLatino\n    <dbl>  <dbl> <dbl>    <dbl>  <dbl>  <dbl>   <dbl>  <dbl>     <dbl>   <dbl>\n1   0.205  0.151 3601.    0.519  0.410  0.250 0.00443  0.148     0.590   0.271\n# ℹ 15 more variables: PForeignborn <dbl>, P_FHHH <dbl>, Pov <dbl>, MHHI <dbl>,\n#   Rvac <dbl>, P_Own <dbl>, MHV <dbl>, CostBurden <dbl>, STUSAB <dbl>,\n#   pct_transit_j2w <dbl>, median_gross_rent <dbl>, pct_hu_1_detached <dbl>,\n#   job_density_simple <dbl>, retail_density_simple <dbl>, median_commute <dbl>\n```\n:::\n:::\n\n\nWe use `vars()` to specify the variables to summarize by their name, using the colon to specify through (e.g. under18 through median_commute). We specify that we want our summary statistic to be the mean, and we specify that we want to remove NAs so we get a usable statistic out. This gives us some usable statistics for the entire region. We might also want to derive summaries for each of the counties in the region - how could we do this using your knowledge of `group_by()`, `substr()`, and `summarise_at()`?\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-20_07b184b06b0389a49e2ac3938fe22a09'}\n\n```{.r .cell-code}\ndataset |> \n  group_by(substr(GEOID, 0, 5)) |> \n  summarise_at(vars(under18:median_commute), mean, na.rm=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: There were 5 warnings in `summarise()`.\nThe first warning was:\nℹ In argument: `STUSAB = (function (x, ...) ...`.\nℹ In group 1: `substr(GEOID, 0, 5) = \"36005\"`.\nCaused by warning in `mean.default()`:\n! argument is not numeric or logical: returning NA\nℹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 26\n  `substr(GEOID, 0, 5)` under18 over65   Pop P_Female PWhite PBlack   PAIAN\n  <chr>                   <dbl>  <dbl> <dbl>    <dbl>  <dbl>  <dbl>   <dbl>\n1 36005                   0.241  0.134 3953.    0.528  0.235  0.344 0.00712\n2 36047                   0.224  0.144 3201.    0.524  0.430  0.313 0.00320\n3 36061                   0.134  0.167 5255.    0.520  0.570  0.142 0.00342\n4 36081                   0.195  0.160 3132.    0.509  0.355  0.200 0.00528\n5 36085                   0.215  0.160 3775.    0.513  0.688  0.124 0.00231\n# ℹ 18 more variables: PAsian <dbl>, PNonwhite <dbl>, PLatino <dbl>,\n#   PForeignborn <dbl>, P_FHHH <dbl>, Pov <dbl>, MHHI <dbl>, Rvac <dbl>,\n#   P_Own <dbl>, MHV <dbl>, CostBurden <dbl>, STUSAB <dbl>,\n#   pct_transit_j2w <dbl>, median_gross_rent <dbl>, pct_hu_1_detached <dbl>,\n#   job_density_simple <dbl>, retail_density_simple <dbl>, median_commute <dbl>\n```\n:::\n:::\n\n\nYou can start to see some of the differences that exist between distributions at the borough (county) level. Do any stick out to you at this point?\n\nOk, we have created a numeric summary table that may be useful for reporting out. Now we can produce our standardized scores which we can use for index making.\n\nNow that you have defined your region, described the data for your region, and know how to standardize the values, you can create a scaled version of your data. Earlier, we learned how to use `summarise_at()` to select variables to summarize using a specific function. There's also a `mutate_at()` function which allows you to perform the same alteration upon all of the variables you select. Take a look at the documentation for `mutate_at()`. You'll need to supply the variables you want to mutate, as well as the function (read closely the documentation and examples before proceeding).\n\nNow let's go ahead and create a **separate** dataset called dataset_scaled which contains the scaled values (there may a few fields which either do not need scaling or who you can remove):\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-21_b852fd53c6ed3f09e9082d607c21a1f0'}\n\n```{.r .cell-code}\ndataset_scaled<-dataset |>  \n  mutate_at(vars(under18, over65, P_Female, PNonwhite, PForeignborn, P_FHHH, Pov, MHHI, P_Own, MHV, CostBurden, CANCER, RESP, PTRAF, PM25, pct_transit_j2w, median_gross_rent, pct_hu_1_detached, job_density_simple, retail_density_simple, median_commute), list(scale=scale))\n```\n:::\n\n\nWe are in the home stretch! We are very close to being able to make our index. We need to determine how we think each variable is related to opportunity. In some cases, higher values are \"good\" (more favorable), and in some cases, lower values are \"good\". We need to make sure that those values are all moving in the same direction so that when we combine them they do not counter-act each other.\n\nBelow is a table proposing potential directions for each variable.\n\n-   **Negative:** For a variable labeled **Negative**, higher values are likely to indicate lower levels of opportunity (less favorable).\n-   **Positive:** Far a variable labeled **Positive**, higher values are likely to indicate higher levels of opportunity (more favorable).\n\n| Variable              | Description                             | Relationship to Opportunity | Category               |\n|----------------|-----------------------|----------------|----------------|\n| under18               | Proportion of Population under 18       | Negative                    | Demographic Structure  |\n| over65                | Proportion of Population over 65        | Negative                    | Demographic Structure  |\n| PNonwhite             | Proportion Population Nonwhite          | Negative                    | Demographic Structure  |\n| PForeignborn          | Proportion Population Foreign Born      | Negative                    | Demographic Structure  |\n| MHHI                  | Median Household Income                 | Positive                    | Employment and Economy |\n| P_FHHH                | Proportion Female Headed Households     | Negative                    | Demographic Structure  |\n| Pov                   | Proportion Households Below Poverty     | Negative                    | Demographic Structure  |\n| P_Own                 | Proportion Owner Occupied Housing Units | Positive                    | Housing                |\n| MHV                   | Median Home Value                       | Positive                    | Housing                |\n| CostBurden            | Housing Cost Burden                     | Negative                    | Housing                |\n| CANCER                | Cancer Risk Index                       | Negative                    | Environmental Health   |\n| RESP                  | Respiratory Hazard Index                | Negative                    | Environmental Health   |\n| PTRAF                 | Traffic Proximity Index                 | Negative                    | Environmental Health   |\n| PM25                  | Particulate Matter Index                | Negative                    | Environmental Health   |\n| pct_transit_j2w       | Commuting by Public Transportation      | Positive                    | Transportation         |\n| median_gross_rent     | Median Gross Rent                       | Negative                    | Housing                |\n| pct_hu_1_detatched    | Detatched Housing Units                 | Positive                    | Housing                |\n| job_density_simple    | Job Density                             | Positive                    | Employment and Economy |\n| retail_density_simple | Retail Density                          | Positive                    | Employment and Economy |\n| median_commute        | Median Commute Time                     | Negative                    | Transportation         |\n\nWe are going to create an \\*\\*additive\\* index, where standardized values are simply added together. We can transform values so that they are moving in the same direction by simply switching the sign on values that need to be reversed (e.g. multiply by -1). Based upon the above table, Here's what that would look like:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-22_98424408815c97fa48f4633e71db9ee2'}\n\n```{.r .cell-code}\ndataset_scaled<-dataset_scaled |>  mutate(\n  under18_scale = under18_scale*-1,\n  over65_scale = over65_scale*-1,\n  PNonwhite_scale = PNonwhite_scale*-1,\n  PForeignborn_scale = PForeignborn_scale*-1,\n  P_FHHH_scale = P_FHHH_scale*-1,\n  Pov_scale = Pov_scale*-1,\n  CostBurden_scale = CostBurden_scale *-1,\n  CANCER_scale = CANCER_scale*-1,\n  RESP_scale = RESP_scale*-1,\n  PTRAF_scale = PTRAF_scale*-1,\n  PM25_scale = PM25_scale*-1,\n  median_gross_rent_scale = median_gross_rent_scale*-1,\n  median_commute_scale = median_commute_scale*-1\n)\n```\n:::\n\n\nBy making these changes, once we add up our indicator values, we are essentially saying that larger values are indicative of greater opportunity and smaller values are indicative of less opportunity. Let's do two things here - we can add up all of our values to get an overall opportunity score, but let's also create sub-indicators for each category, as this may be useful information for us to observe.\n\nTo do this, add several new variables to dataset_scaled that sum together each of the index measures by category, and then create a separate indicator that sums up those category columns into an overall opportunity measure:\n\nUse the following labels:\n\n-   dem_index = Demographic Structure\n-   emp_index = Employment and Economy\n-   hou_index = Housing\n-   env_index = Environmental Health\n-   tra_index = Transportation\n-   tot_index = Combined Total Index\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-23_7acf13692303630b65ee7a4172d27e96'}\n\n```{.r .cell-code}\ndataset_scaled<-dataset_scaled |> \n  rowwise() |> \n  mutate(\n  dem_index = sum(under18_scale, over65_scale, PNonwhite_scale, PForeignborn_scale, P_FHHH_scale, Pov_scale, na.rm=TRUE),\n  emp_index = sum(MHHI_scale, job_density_simple_scale, retail_density_simple_scale, na.rm=TRUE),\n  hou_index = sum(P_Own_scale, MHV_scale, CostBurden_scale, median_gross_rent_scale, pct_hu_1_detached_scale, na.rm=TRUE),\n  env_index = sum(CANCER_scale, RESP_scale, PTRAF_scale, PM25_scale, na.rm=TRUE),\n  tra_index = sum(pct_transit_j2w_scale, median_commute_scale,na.rm=TRUE),\n  tot_index = dem_index + emp_index + hou_index + env_index + tra_index\n) \n```\n:::\n\n\nSomething's a little different here that makes a big difference. Did you notice `rowwise()`? Typically, if we were to ask dplyr to mutate by providing a sum, it would do so by column. `rowwise()` modifies this and asks for something to happen across a data observation (row) instead of by column. Therefore, when we ask in a mutate statement for the sum of values, we are asking R to add up the values in the same row and then insert the product into a new variable (in this case our named indexes). Pretty cool, right?\n\nOk - now we have subindex values as well as a total index value. We could analyze these and interpret them as is, but there's one more thing that we might do to make these easier to interpret. Let's quickly look at some descriptive stats for our index values and think about what may be challenging for us to interpret:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-24_d1bf4f13fea59ddee6c167f74a98db0c'}\n\n```{.r .cell-code}\ndataset_scaled |> \n  select(dem_index, emp_index, hou_index, env_index, tra_index, tot_index) |> \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   dem_index          emp_index         hou_index         env_index      \n Min.   :-10.7759   Min.   :-2.4750   Min.   :-7.3245   Min.   :-14.084  \n 1st Qu.: -2.1811   1st Qu.:-0.8973   1st Qu.:-1.5020   1st Qu.: -1.639  \n Median : -0.1554   Median :-0.3840   Median :-0.1535   Median :  0.000  \n Mean   :  0.0000   Mean   : 0.0000   Mean   : 0.0000   Mean   :  0.000  \n 3rd Qu.:  2.1316   3rd Qu.: 0.1484   3rd Qu.: 1.1933   3rd Qu.:  1.443  \n Max.   : 11.8808   Max.   :31.0470   Max.   :10.5857   Max.   :  9.302  \n   tra_index         tot_index      \n Min.   :-6.7759   Min.   :-19.994  \n 1st Qu.:-0.8376   1st Qu.: -3.762  \n Median : 0.0000   Median :  0.000  \n Mean   : 0.0000   Mean   :  0.000  \n 3rd Qu.: 1.1383   3rd Qu.:  3.605  \n Max.   : 3.3514   Max.   : 35.604  \n```\n:::\n:::\n\n\nLooking at this, there are a few challenges:\n\n-   Since each subindex component consists of between two and six values, they end up having very different scales. This means that we can't interpret anything about the magnitude by comparing these values to each other.\n-   We have both positive and negative index values. Negative values don't necessarily mean anything other than that the sum of index values is negative.\n\nOne strategy for making these values more interpretable is to **rescale** them. Do not confuse *rescaling* with the type of *standardizing* which we previously performed by converting our indicator values into z scores. Rescaling will take the data from an existing range and convert it to a new range of values.\n\nRescaling converts our data from its existing range of values to a new range of values, preserving the magnitude of difference that exists between the values:\n\nIf we want to convert our data to the range \\[0,1\\] here's what we'd do: $x_{rescaled} = \\frac{x-min(x)}{max(x)-min(x)}$\n\nWe can also convert our data to an arbitrary range. Let's try 0,100: $x_{rescaled} = a+\\frac{x-min(x)(b-a)}{max(x) -min(x)}$\n\nFortunately, R has us covered here too - the `rescale` function in the `scales` package will rescale to whatever range we wish:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-25_251b0a15fe86a108d9489ff03a2634bd'}\n\n```{.r .cell-code}\nlibrary(scales)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'scales'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    discard\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:readr':\n\n    col_factor\n```\n:::\n\n```{.r .cell-code}\ndataset_scaled <-dataset_scaled |> \n  ungroup() |> \n  mutate(dem_index = rescale(dem_index, to = c(0,100)),\n         emp_index = rescale(emp_index, to = c(0,100)),\n         hou_index = rescale(hou_index, to = c(0,100)),\n         env_index = rescale(env_index, to = c(0,100)),\n         tra_index = rescale(tra_index, to = c(0,100)),\n         tot_index = rescale(tot_index, to = c(0,100))\n  )\n\ndataset_scaled |>  \n  select(dem_index, emp_index, hou_index, env_index, tra_index, tot_index) |> \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   dem_index        emp_index         hou_index        env_index     \n Min.   :  0.00   Min.   :  0.000   Min.   :  0.00   Min.   :  0.00  \n 1st Qu.: 37.93   1st Qu.:  4.707   1st Qu.: 32.51   1st Qu.: 53.22  \n Median : 46.88   Median :  6.238   Median : 40.04   Median : 60.23  \n Mean   : 47.56   Mean   :  7.383   Mean   : 40.90   Mean   : 60.23  \n 3rd Qu.: 56.97   3rd Qu.:  7.826   3rd Qu.: 47.56   3rd Qu.: 66.40  \n Max.   :100.00   Max.   :100.000   Max.   :100.00   Max.   :100.00  \n   tra_index        tot_index     \n Min.   :  0.00   Min.   :  0.00  \n 1st Qu.: 58.64   1st Qu.: 29.20  \n Median : 66.91   Median : 35.96  \n Mean   : 66.91   Mean   : 35.96  \n 3rd Qu.: 78.15   3rd Qu.: 42.45  \n Max.   :100.00   Max.   :100.00  \n```\n:::\n:::\n\n\nThe values are all rescaled so that the minimum is now zero and the maximum value is 100. We use `ungroup()` here so that if we have used `group_by()` in the past, R ignores those past groupings when we rescale. Looking at the descriptive statistics for these variables, there's still some **skew** in many cases. We might want to try visualizing these distributions so that we can better understand their implications.\n\n# Visualizing Index Values\n\nLet's start our data visualization by making a simple histogram of values for our tot_index measure:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-26_b346f9f311fa711f7476e3311cbba137'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tot_index))+geom_histogram()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nWhat's going on here? We call `ggplot` (`ggplot()`) and then start adding layers to our plot. In its most basic form, ggplot needs to know the data source, as well as some aesthetic mappings for the data. The data source can be called by name, and the aesthetic mappings are placed in `aes()'. After this, we can specify a format for our plot by asking it to plot using a particular geometry, in this case`geom_histogram()\\`.\n\nYou have probably observed that ggplot tells us that it is using a somewhat arbitrary bin width for our histogram. We can select another one by adding to the histogram geometry a specification for a different number of bins:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-27_4a7286167a4873bb4a74b6e1e0ec0f24'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tot_index))+geom_histogram(bins=100)\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nNotice, we go from 30 bins to 100 bins, meaning that they become much narrower as each captures and counts a smaller range of the data.\n\nWe can add other elements to our plot that help to make it look nice:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-28_46e739afbe1778988efa5555a46af472'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tot_index))+geom_histogram(bins=100)+\n  labs(title = \"Opportunity Index: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\nHave a look at the [ggplot2 cheat sheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf) for some inspiration on how you can alter your plots further.\n\nLet's produce similar histograms for each of the subindex components. Feel free to play around with some of the aesthetics just for fun!\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-29_8a478c2a18332ca3427012c3334e9f56'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=dem_index))+geom_histogram(bins=100)+\n  labs(title = \"Demographic Structure Subindex: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=emp_index))+geom_histogram(bins=100)+\n  labs(title = \"Employment and Economy Subindex: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-29-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=hou_index))+geom_histogram(bins=100)+\n  labs(title = \"Housing Subindex: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-29-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=env_index))+geom_histogram(bins=100)+\n  labs(title = \"Environmental Health Subindex: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-29-4.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tra_index))+geom_histogram(bins=100)+\n  labs(title = \"Transportation Subindex: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-29-5.png){width=672}\n:::\n:::\n\n\nReferring back to the [ggplot2 cheat sheet](https://rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf), try your hand at some other one variable visualizations (good places to start would be `geom_area`, `geom_density`, and `geom_bar`:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-30_fc39ccf3a90fc36fc40c59465c92f72d'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tra_index))+geom_area(stat=\"bin\", bins=100)+\n  labs(title = \"Transportation Subindex: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n## Demographics by Opportunity Levels\n\nLet's take a look at our overall opportunity index again:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-31_b33bdccdefa8899439757377c3e73634'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tot_index))+geom_histogram(bins=100)+\n  labs(title = \"Opportunity Index: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-31-1.png){width=672}\n:::\n:::\n\n\nHow might we start to think about some of the demographic correlates of who lives in places with higher aggregate opportunity and lower aggregate opportunity? You'll recall from when we initially created our index that we had downloaded some information on race and ethnicity which was not incorporated into our opportunity measures. We might be interested to see how our composite measure of low and high opportunity are related to the racial and ethnic composition of the census tracts they are from.\n\nWe might turn towards a some bivariate visualizations to help us here. Let's start with a simple scatterplot:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-32_684d96b4983729473867b915531a641c'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =tot_index))+geom_point()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\nHow would you describe the relationship visualized here (note that I shifted the index values to the y scale and placed percent white on the x scale)? To make it easier, let's add another geometry to the same plot, in this case, by fitting a line to our data:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-33_786c3744cf80a9246fdd58477324382d'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =tot_index))+geom_point()+geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\nHow would you describe the relationship between the tract-level concentration of the white population and the overall index score?\n\nWe might want to polish things up a little more - here are some suggested additions to think about.\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-34_9840d8e9fd7d191a630cde7e73d76ac2'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =tot_index))+\n  geom_point(alpha = .6, cex = .75)+ # Use alpha to control the transparency of the points and cex to control their size\n  geom_smooth(method = \"lm\")+\n  labs(x=\"White (%)\", y = \"Combined Opportunity Index\")+ # Add labels to the x and y axes\n  scale_x_continuous(labels = scales::percent)+ # Use the scales package to convert X-axis to percentages\n  theme_minimal() #Use themes to eliminate extra shading on plots\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nYour turn - produce similar plots for the Black, Asian, and Latino populations:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-35_bbef50129ebcccb4d4b78235f527ea99'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PBlack, y =tot_index))+geom_point()+geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-35-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PAsian, y =tot_index))+geom_point()+geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-35-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PLatino, y =tot_index))+geom_point()+geom_smooth(method = \"lm\")\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-35-3.png){width=672}\n:::\n:::\n\n\n# How different are counties in the region?\n\nSo far, we've been looking at opportunity scores for the New York City. The values we see are likely to be very different for different boroughs. Let's disaggregate and make some comparisons.\n\nAs a reminder, here are the county FIPS codes for the boroughs in the city:\n\n| FIPS Code | County Name     | Borough Name  |\n|-----------|-----------------|---------------|\n| 36047     | Kings County    | Brooklyn      |\n| 36005     | Bronx County    | Bronx         |\n| 36081     | Queens County   | Queens        |\n| 36085     | Richmond County | Staten Island |\n| 36061     | New York County | Manhattan     |\n\nLet's label each tract by the borough (county) that contains it.\n\nWe used `case_when()` in the past. `case_when()` allows us to set up multiple conditions to search for, and then we can determine what to do when we have found records which match that condition:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-36_c1321cb545932e20025b6e38c0e2b040'}\n\n```{.r .cell-code}\ndataset_scaled<-dataset_scaled |> \n  mutate(location = case_when(\n  substr(GEOID, 0,5) == \"36047\" ~ \"Brooklyn\",\n  substr(GEOID, 0,5) == \"36005\" ~ \"Bronx\",\n  substr(GEOID, 0,5) == \"36081\" ~ \"Queens\",\n  substr(GEOID, 0,5) == \"36085\" ~ \"Staten Island\",\n  substr(GEOID, 0,5) == \"36061\" ~ \"Manhattan\"\n))\n```\n:::\n\n\nIn this case, we create a new variable called location, and then label those records where the county FIPS code is equal to a particular county.\n\nNow that we have this new differentiating variable, we can modify our existing plots to illustrate differences between boroughs. We can start by **faceting** our existing chart. Facets take categorical variables and split the chart into as many multiples as there are categories. In our case, we can use our new location variable as a facet, so we should expect five multiples in an updated chart:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-37_54c29adece2c3cbbbdf2768486f25845'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tot_index))+geom_histogram(bins=100)+\n  labs(title = \"Opportunity Index: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()+\n  facet_wrap(~location)\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n:::\n\n\nThe tilde (`~`) is necessary before listing the variable you want to facet.\n\nThis gives us a sense of the relative shape and distribution of opportunity index values for each county. As an alternative strategy to use our facets, we might want to set our scales to \"free\" in our histogram settings so that we can better compare the shape of our histograms. The distortion we see is due to Brooklyn and Queens having more tracts, thereby creating higher peaks within any given bin. By setting scales to \"free\", ggplot sets the scales based upon the range of data contained only within a given facet instead of across all facets:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-38_811e34354268adf4cdc9517e774488b0'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=tot_index))+geom_histogram(bins=100)+\n  labs(title = \"Opportunity Index: Histogram\", x=\"Opportunity Index\", y=\"Count\")+\n  theme_classic()+\n  facet_wrap(~location, scales = \"free\")\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\nWhat can this tell us about the distribution of opportunity scores within each borough in New York City?\n\nNow go ahead and re-create the scatterplot we previously created that compared the White population on the x axis to the overall opportunity index score on the y axis. Be sure to facet by location. Go ahead and add a summary line of best fit as well.\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-39_1001c2b4f3293afdc5cb68bc13d92d41'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =tot_index))+geom_point()+geom_smooth(method = \"lm\")+\n  facet_wrap(~location)+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\nLet's try faceting subindex values to see how they differ. Are there any that you can see any substantial visual differences on? How would you explain the differences that you see?\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-40_e09bdb4f2719400656d034f5f31b4caa'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =dem_index))+geom_point()+geom_smooth(method = \"lm\")+\n  facet_wrap(~location)\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =emp_index))+geom_point()+geom_smooth(method = \"lm\")+\n  facet_wrap(~location)\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-40-2.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =hou_index))+geom_point()+geom_smooth(method = \"lm\")+\n  facet_wrap(~location)\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-40-3.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =env_index))+geom_point()+geom_smooth(method = \"lm\")+\n  facet_wrap(~location)\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-40-4.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =tra_index))+geom_point()+geom_smooth(method = \"lm\")+\n  facet_wrap(~location)\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-40-5.png){width=672}\n:::\n:::\n\n\nSo far, we have learned how to display fit regression lines on top of our point data. Sometimes, it can be useful to simply display those lines without the associated point data. As part of our aesthetic mapping, we can set a grouping variable (group), and also tell ggplot to vary the colour (British spelling, please) of each group. In this case, we set both of these based upon the location variable:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-41_3a996bbf0f07191c49c5823e16002bb7'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =tot_index, group=location, colour=location))+geom_smooth(method = \"lm\")+\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\nHow would you interpret the differences between the two lines (without points)? Can you re-create similar graphics for some of the subindex categories or other racial identifications?\n\nFinally, let's combine some of what we've learned here to visualize groups for both the point data and the associated regression lines:\n\n\n::: {.cell hash='08_placeopportunity_cache/html/unnamed-chunk-42_208a7012d8d6654cbd59d8aa1308dc84'}\n\n```{.r .cell-code}\nggplot(data=dataset_scaled, aes(x=PWhite, y =tot_index, group=location, colour=location))+\n  geom_point(alpha=.075)+\n  geom_smooth(method = \"lm\", se=FALSE, alpha = .1)+\n  labs(x = \"White Population (%)\", y = \"Opportunity Index\", colour = \"County\")+\n  scale_x_continuous(labels = scales::percent)+\n  theme_classic()\n```\n\n::: {.cell-output-display}\n![](08_placeopportunity_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\nI have used `theme_classic()` here to remove the gray background which I think makes it difficult to see the points and lines well. In the point geometries, I have used the *alpha* value to alter the transparency of the points. This can help us to see some of the differences between boroughs. If you look carefully, you'll also see that there is a rather dense cluster of tracts that are mostly non-white with relatively high opportunity scores in Queens. In this chart, we can also see how those tracts with a high proportion of white people and high index values are what is likely bringing up the slope of the regression line for the total index.\n\nSpend some time playing around with these visualizations using different aesthetic mappings and different x and y variables. Think about how you can creatively layer different components and also about the types of stories that you can tell about opportunity in Illinois.\n\n## Extending your Analysis\n\nThe most standard next step in opportunity mapping is...\n\n-   Making a map. Drawing from your index data, make a map of your overall index score for your place or region, as well as for index sub-components. What spatial patterns emerge? Map out key demographic information - how do these seem to be related to your overall measures of opportunity?\n-   Create summary visualizations and tables that display where the highest and lowest levels of opportunity are within the region? Who lives in these places?\n-   Consider connecting your opportunity indexes to other data (examples might include public health statistics, transportation costs, presence of public or subsidized housing, etc.) How does a multidimensional opportunity index help you tell stories about these places?\n-   Create a journalistic narrative about opportunity in your place or for another region. What makes your story powerful, and what story is it telling?\n\n## Lab Evaluation\n\nIn evaluating your lab submission, we'll be paying attention to the following:\n\n1.  A demonstrated conceptual understanding of the opportunity concept and the way it becomes operationalized with quantitative demographic data.\n2.  Correct re-deployment of the code based used in this lab for your own place or region.\n3.  A clear narrative analysis of opportunity for your place.\n4.  Proper formatting of tables, figures, and visualizations.\n\nAs you get into the lab, please feel welcome to ask us questions, and please share where you're struggling with us and with others in the class.\n\n## References\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}